<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[冒泡和快排]]></title>
    <url>%2F2018%2F09%2F12%2F%E5%86%92%E6%B3%A1%E5%92%8C%E5%BF%AB%E6%8E%92%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&apos;&apos;&apos;冒泡排序的概念:取出列表中的当前值与下一个值进行比较，比较完成后，向列表的最后方或最前方浮动（一次浮动一个位置）外层for循环-&gt;控制列表中余下比较元素的个数内层for循环-&gt;控制当前循环比较的元素&apos;&apos;&apos;#冒泡排序def maoPao(infos): for i in range(len(infos) - 1): for j in range(len(infos) - 1 - i): if infos[j] &gt; infos[j+1]: infos[j],infos[j+1] = infos[j+1],infos[j] return infos #列表lists使用冒泡从小到大排序lists = [33,12,8,88,10,6,5,18]res = maoPao(lists)print(res) &apos;&apos;&apos;快排的概念:取出需要排序的列表中的第一个（下面案例为取出第一个）或者最后一个元素，作为参照元素使用for循环，拿列表中第[1:last]（第二个到最后一个元素）依次和列表的第一个元素进行比较如果for循环的当前元素比第一个元素大，则定义一个max列表，并把当前元素加入其中如果for循环的当前元素比第一个元素小，则定义一个min列表，并把当前元素加入其中若返回从小到大的排序，则使用 |min + 第一个值（列表中的比较元素）+ max| 返回注意返回列表中的min和max列表，应使用递归函数，再次调用当前排序函数最后在排序函数逻辑开始的地方判断传入的列表（需要排序的列表）长度是否&lt;=1（小于等于1）如果满足&lt;=1则返回正在递归中的传入列表&apos;&apos;&apos;#快速排序（快排）#普通写法def quick(infos): if len(infos) &lt;= 1: return infos mins = [] maxs = [] for v in infos[1:]: if v &gt; infos[0]: maxs.append(v) elif v &lt; infos[0]: mins.append(v) return quick(mins) + infos[0:1] + quick(maxs)#注意！这里如果用info[0]取值，取出的时列表中的int值。所以return拼接的列表时，应用infos[0:1]取值，这样取出的是一个内含一个元素的列表，返回拼接列表的时候就不会报错了！ lists = [33,12,8,88,10,6,5,18]res = quick(lists)print(res) #list推导式写法def quick_tds(infos): if len(infos) &lt;= 1: return infos return quick_tds([v for v in infos[1:] if v&lt;infos[0]] + infos[0:1]) + quick_tds([v for v in infos[1:] if v&gt;infos[0]]) lists = [33,12,8,88,10,6,5,18]res = quick_tds(lists)print(res)]]></content>
  </entry>
  <entry>
    <title><![CDATA[ES]]></title>
    <url>%2F2018%2F09%2F12%2FES%2F</url>
    <content type="text"><![CDATA[ES定义ES=elasticsearch简写， Elasticsearch是一个开源的高扩展的分布式全文检索引擎，它可以近乎实时的存储、检索数据；本身扩展性很好，可以扩展到上百台服务器，处理PB级别的数据。Elasticsearch也使用Java开发并使用Lucene作为其核心来实现所有索引和搜索的功能，但是它的目的是通过简单的RESTful API来隐藏Lucene的复杂性，从而让全文搜索变得简单。 ES的核心概念 Cluster：集群。ES可以作为一个独立的单个搜索服务器。不过，为了处理大型数据集，实现容错和高可用性，ES可以运行在许多互相合作的服务器上。这些服务器的集合称为集群。 Node：节点。形成集群的每个服务器称为节点。 Shard：分片。当有大量的文档时，由于内存的限制、磁盘处理能力不足、无法足够快的响应客户端的请求等，一个节点可能不够。这种情况下，数据可以分为较小的分片。每个分片放到不同的服务器上。当你查询的索引分布在多个分片上时，ES会把查询发送给每个相关的分片，并将结果组合在一起，而应用程序并不知道分片的存在。即：这个过程对用户来说是透明的。 Replia：副本。为提高查询吞吐量或实现高可用性，可以使用分片副本。副本是一个分片的精确复制，每个分片可以有零个或多个副本。ES中可以有许多相同的分片，其中之一被选择更改索引操作，这种特殊的分片称为主分片。当主分片丢失时，如：该分片所在的数据不可用时，集群将副本提升为新的主分片。 全文检索。全文检索就是对一篇文章进行索引，可以根据关键字搜索，类似于mysql里的like语句。全文索引就是把内容根据词的意义进行分词，然后分别创建索引，例如”你们的激情是因为什么事情来的” 可能会被分词成：“你们“，”激情“，“什么事情“，”来“ 等token，这样当你搜索“你们” 或者 “激情” 都会把这句搜出来。 ES的使用使用Docker安装Elasticsearch及其扩展获取镜像，可以通过网络pull 1docker image pull delron/elasticsearch-ik:2.4.6-1.0 或者加载提供给大家的镜像文件 1docker load -i elasticsearch-ik-2.4.6_docker.tar 修改elasticsearch的配置文件 elasticsearc-2.4.6/config/elasticsearch.yml第54行，更改ip地址为本机ip地址 1network.host: 自己机器的IP地址 创建docker容器运行 1docker run -dti --network=host --name=elasticsearch -v /home/python/elasticsearch-2.4.6/config:/usr/share/elasticsearch/config delron/elasticsearch-ik:2.4.6-1.0 使用haystack对接ElasticsearchHaystack为Django提供了模块化的搜索。它的特点是统一的，熟悉的API，可以让你在不修改代码的情况下使用不同的搜索后端（比如 Solr, Elasticsearch, Whoosh, Xapian 等等）。我们在django中可以通过使用haystack来调用Elasticsearch搜索引擎。 安装 12pip install drf-haystackpip install elasticsearch==2.4.1 注册应用 1234INSTALLED_APPS = [ ... &apos;haystack&apos;,] 配置 12345678910111213# HaystackHAYSTACK_CONNECTIONS = &#123; &apos;default&apos;: &#123; &apos;ENGINE&apos;: &apos;haystack.backends.elasticsearch_backend.ElasticsearchSearchEngine&apos;, # 端口号固定为9200 &apos;URL&apos;: &apos;http://es的IP:9200/&apos;, # 指定elasticsearch建立的索引库的名称 &apos;INDEX_NAME&apos;: &apos;meiduo_mall&apos;, &#125;,&#125;# 当添加、修改、删除数据时，自动生成索引HAYSTACK_SIGNAL_PROCESSOR = &apos;haystack.signals.RealtimeSignalProcessor&apos; 注意：HAYSTACK_SIGNAL_PROCESSOR 的配置保证了在Django运行起来后，有新的数据产生时，haystack仍然可以让Elasticsearch实时生成新数据的索引。]]></content>
  </entry>
  <entry>
    <title><![CDATA[middleware]]></title>
    <url>%2F2018%2F09%2F12%2Fmiddleware%2F</url>
    <content type="text"><![CDATA[中间件Django中的中间件是一个轻量级、底层的插件系统，可以介入Django的请求和响应处理过程，修改Django的输入或输出。中间件的设计为开发者提供了一种无侵入式的开发方式，增强了Django框架的健壮性。 中间件的定义方法定义一个中间件工厂函数，然后返回一个可以别调用的中间件。中间件工厂函数需要接收一个可以调用的get_response对象。返回的中间件也是一个可以被调用的对象，并且像视图一样需要接收一个request对象参数，返回一个response对象。 12345678910111213def simple_middleware(get_response): # 此处编写的代码仅在Django第一次配置和初始化的时候执行一次。 def middleware(request): # 此处编写的代码会在每个请求处理视图前被调用。 response = get_response(request) # 此处编写的代码会在每个请求处理视图之后被调用。 return response return middleware 定义好中间件后，需要在settings.py 文件中添加注册中间件。 多个中间件的执行顺序 在请求视图被处理前，中间件由上至下依次执行 在请求视图被处理后，中间件由下至上依次执行]]></content>
  </entry>
  <entry>
    <title><![CDATA[orm框架]]></title>
    <url>%2F2018%2F09%2F12%2Form%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[概念对象关系映射（Object Relational Mapping，简称ORM）模式是一种为了解决面向对象与关系数据库存在的互不匹配的现象的技术。 ORM的方法论基于三个核心原则： 简单：以最基本的形式建模数据。 传达性：数据库结构被任何人都能理解的语言文档化。 精确性：基于数据模型创建正确标准化了的结构。 ORM技术特点 1.提高了开发效率。由于ORM可以自动对Entity对象与数据库中的Table进行字段与属性的映射，所以我们实际可能已经不需要一个专用的、庞大的数据访问层。 2.ORM提供了对数据库的映射，不用sql直接编码，能够像操作对象一样从数据库获取数据。 ORM的优缺点ORM的缺点是会牺牲程序的执行效率和会固定思维模式。从系统结构上来看,采用ORM的系统一般都是多层系统，系统的层次多了，效率就会降低。ORM是一种完全的面向对象的做法，而面向对象的做法也会对性能产生一定的影响。在我们开发系统时，一般都有性能问题。性能问题主要产生在算法不正确和与数据库不正确的使用上。ORM所生成的代码一般不太可能写出很高效的算法，在数据库应用上更有可能会被误用，主要体现在对持久对象的提取和和数据的加工处理上，如果用上了ORM,程序员很有可能将全部的数据提取到内存对象中，然后再进行过滤和加工处理，这样就容易产生性能问题。在对对象做持久化时，ORM一般会持久化所有的属性，有时，这是不希望的。 Django中使用ORMdjango中内嵌了ORM框架，不需要直接面向数据库编程，而是定义模型类，通过模型类和对象完成数据表的增删改查操作。 使用django进行数据库开发的步骤如下：1.配置数据库连接信息2.在models.py中定义模型类3.迁移4.通过类和对象完成数据增删改查操作orm作用：]]></content>
  </entry>
  <entry>
    <title><![CDATA[git版本控制]]></title>
    <url>%2F2018%2F09%2F12%2Fgit%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[GIT介绍Git(读音为/gɪt/。)是一个开源的分布式版本控制系统，可以有效、高速的处理从很小到非常大的项目版本管理。 [1] Git 是 Linus Torvalds 为了帮助管理 Linux 内核开发而开发的一个开放源码的版本控制软件。 git开发过程从一般开发者角度来看，git有以下功能：1.从服务器上克隆完整的Git仓库（包括代码和版本信息）到单机上。2.在自己的机器上根据不同的开发目的，创建分支，修改代码。3.在单机上自己创建的分支上提交代码。4.在单机上合并分支。5.把服务器上最新版的代码fetch下来，然后跟自己的主分支合并。6.生成补丁（patch），把补丁发送给主开发者。7.看主开发者的反馈，如果主开发者发现两个一般开发者之间有冲突（他们之间可以合作解决的冲突），就会要求他们先解决冲突，然后再由其中一个人提交。如果主开发者可以自己解决，或者没有冲突，就通过。8.一般开发者之间解决冲突的方法，开发者之间可以使用pull 命令解决冲突，解决完冲突之后再向主开发者提交补丁。 从主开发者（假设主开发者不用开发代码）角度来看，git有以下功能：1.查看邮件或者通过其它方式查看一般开发者的提交状态。2.打上补丁，解决冲突（可以自己解决，也可以要求开发者之间解决以后再重新提交，如果是开源项目，还要决定哪些补丁有用，哪些不用）。3.向公共服务器提交结果，然后通知所有开发人员。 git的常用操作1.版本库创建一个版本库：git init2.增加内容增加内容跟踪信息：git add3.提交内容提交内容到版本库：git commit例：git commit -m “Initial commit of git tutor reposistory”4.查看版本库的信息git status5.查看当前的工作：git diffgit diff 命令将比较当前的工作目录和版本库数据库中的差异。现在我们编辑一些文件来体验一下 git 的跟踪功能。6.管理分支管理分支：git branch 创建分支更简单和常用的方法是直接通过 checkout 命令来一次性创建并转移到新建分支上，命令如下：$ git checkout -b robin [start_point]其中 start_point 是一个可选参数，指定新建分支 robin 是基于哪个节点，默认为当前所在分支的节点。 删除分支要删除版本库中的某个分支，使用 git branch -d 命令就可以了：git branch -d branch-name 7.这个命令让我们看到版本库的发展记录。$ git show-branch8.合并分支合并两个分支：git merge9.设置全局编码，防止代码乱码git config –global gui.encoding utf-810.把本地分支推送到服务器分支上–u表示如果仓库没有则新建一个：git push –u origin master[默认是master，如果有版本号则填写版本号]11.git log 这是一个帮助我们查看历史提交信息的命令； 直接使用git log命令将会输出历史所有的提交信息，有时我们只需要查看进几次的提交信息，就可以使用-选项来显式指定输出的commit次数； 我们也可以使用-pretty=xxx参数来指定输出的提交信息的简易程度，有以下一些参数值可供选择，oneline，short，full 和 fuller； 还有一个选项是-p，我们往往对于某次提交都是会附带描述信息的，但是有时候这些描述信息不是很准确，而我们又想确定此次提交做出了那些修改，这时可以使用-p选项来输出此次提交的修改内容；12.git reset 我们使用git最重要的一个目的就是，随时可以回退历史版本，而我们的reset命令就是完成这个工作的。例如：我们在git工作区创建一个文件index然后做一次提交（描述信息one），然后我们为index文件键入一些内容，再一次提交（描述信息two），这样我们构建了两次提交，最新一次的提交为two，我们可以利用reset回退到one。13.git clone当我们遇到比较好的开源项目并想要参与其中的时候，我们就需要获取到别人项目的所有代码，这时候我们的clone命令就可以发挥作用了。我们在远程服务器上上创建一个库，新建一个文件index.txt，然后我们利用clone命令完成拷贝远程仓库的动作。 gitlab与github的区别1.相同点：先说一下相同点，二者都是基于web的Git仓库，在很大程度上GitLab是仿照GitHub来做的，它们都提供了分享开源项目的平台，为开发团队提供了存储、分享、发布和合作开发项目的中心化云存储的场所。2.GitLab让开发团队对他们的代码仓库拥有更多的控制，相比于GitHub，它有不少的特色： 允许免费设置仓库权限；允许用户选择分享一个project的部分代码；允许用户设置project的获取权限，进一步的提升安全性；可以设置获取到团队整体的改进进度；通过innersourcing让不在权限范围内的人访问不到该资源。 从代码私有性方面来看，有时公司并不希望员工获取到全部的代码，这个时候GitLab无疑是更好的选择。但对于开源项目而言，GitHub依然是代码托管的首选。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Redis数据库]]></title>
    <url>%2F2018%2F09%2F12%2FRedis%E6%95%B0%E6%8D%AE%E5%BA%93%2F</url>
    <content type="text"><![CDATA[关系型数据库关系型数据库最典型的数据结构是表，由二维表及其之间的联系所组成的一个数据组织。优点：1.易于维护：都是使用表结构，格式一致；2.使用方便：SQL语言通用，可用于复杂查询；3.复杂操作：支持SQL，可用于一个表以及多个表之间非常复杂的查询。缺点：1.读写性能比较差，尤其是海量数据的高效率读写；2.固定的表结构，灵活度稍欠；3.高并发读写需求，传统关系型数据库来说，硬盘I/O是一个很大的瓶颈。 非关系型数据库非关系型数据库严格上不是一种数据库，应该是一种数据结构化存储方法的集合，可以是文档或者键值对等。优点：1.格式灵活：存储数据的格式可以是key,value形式、文档形式、图片形式等等，文档形式、图片形式等等，使用灵活，应用场景广泛，而关系型数据库则只支持基础类型。2.速度快：nosql可以使用硬盘或者随机存储器作为载体，而关系型数据库只能使用硬盘；3.高扩展性；4.成本低：nosql数据库部署简单，基本都是开源软件。缺点：1.不提供sql支持，学习和使用成本较高；2.无事务处理；3.数据结构相对复杂，复杂查询方面稍欠。非关系型数据库的分类：1.文档型2.key-value型3.列式数据库4.图形数据库 Redis介绍redis是一个开源的、使用C语言编写的、支持网络交互的、可基于内存也可持久化的Key-Value数据库。 Redis与其他key-value缓存产品有以下三个特点：1.Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启时候可以再次加载进行使用。2.Redis不仅仅支持简单的key-redis类型的数据，同事还提供了list，set，zset，hash等数据结构的存储。3.Redis支持数据的备份，即master-slave模式的数据备份。 redis是一种高级的key:value存储系统，其中value支持五种数据类型：string常用命令：set,get,decr,incr,mget 等，list常用命令：lpush,rpush,lpop,rpop,lrange等，set常用命令：sadd,spop,smembers,sunion等，zset常用命令：zadd,zrange,zrem,zcard 等，hash常用命令：hget,hset,hgetall 等 Redis的优势 性能极高 Redis能读的速度是110000次每秒，写的速度是81000次每秒。 丰富的数据类型 Redis支持二进制案例的 String，List，Hashes，Sers(无序集合)及Ordered Sers(有序集合)数据类型的操作 原子 Redis的所有操作都是原子性的，同时Redis还支持对集合操作合并后的原子性的执行。 Redis的应用场景 用来作缓存(ehcache/memcached) redis的所有数据是放在内存中的 可以在某些特定的应用场景下替换传统的数据库 比如社交类的应用 在一些大型系统中，巧妙地实现一些特定的功能：购物车等 Redis五种类型的操作方式http://doc.redisfans.com/ Redis数据库的默认端口，默认过期时间，Value 最多可以容纳的数据 长度1.默认端口：63792.默认过期时间：可以说永不过期，一般情况下，当配置中开启了超出最大内存限制就写磁盘的话，那么没有设置过期时间的 key 可能会被写到磁盘上。假如没设置，那么REDIS将使用 LRU 机制，将内存中的老数据删除，并写入新数据。3.Value 最多可以容纳的数据长度是：512M Redis 缓存命中率计算Redis 提供了INFO 这个命令，能够随时监控服务器的状态，只用telnet 到对应服务器的端口，执行命令即可： 123456789telnet localhost 6379info在输出的信息里面有这几项和缓存的状态比较有关系：keyspace_hits:144141101. keyspace_misses:3228654 2. used_memory:433264648 3. expired_keys:1333536 4. evicted_keys:1547380 通过计算hits和miss，我们可以得到缓存的命中率： 14414110 / (14414110 +3228654)= 81% ，一个缓存失效机制，和过期时间设计良好的系统，命中率可以做到95%以上。 Redis有多少个库Redis 一个实例下有 16个库 Redis受到攻击怎么办？1.主从2.持久化存储3.Redis不以Root账户启动4.设置复杂的密码5.不允许以key方式登陆 Redis持久化的方式由于Redis的数据都存放在内存中，如果没有配置持久化，redis重启后数据就全丢失了，于是需要开启redis的持久化功能，将数据保存到磁盘上，当redis重启后，可以从磁盘中恢复数据。redis提供两种方式进行持久化，一种是RDB持久化（原理是将Reids在内存中的数据库记录定时dump到磁盘上的RDB持久化），另外一种是AOF（append only file）持久化（原理是将Reids的操作日志以追加的方式写入文件）。二者区别：RDB持久化是指在指定的时间间隔内将内存中的数据集快照写入磁盘，实际操作过程是fork一个子进程，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储。 AOF持久化以日志的形式记录服务器所处理的每一个写、删除操作，查询操作不会记录，以文本的方式记录，可以打开文件看到详细的操作记录。 RDB优势1). 一旦采用该方式，那么你的整个Redis数据库将只包含一个文件，这对于文件备份而言是非常完美的。比如，你可能打算每个小时归档一次最近24小时的数据，同时还要每天归档一次最近30天的数据。通过这样的备份策略，一旦系统出现灾难性故障，我们可以非常容易的进行恢复。 2). 对于灾难恢复而言，RDB是非常不错的选择。因为我们可以非常轻松的将一个单独的文件压缩后再转移到其它存储介质上。 3). 性能最大化。对于Redis的服务进程而言，在开始持久化时，它唯一需要做的只是fork出子进程，之后再由子进程完成这些持久化的工作，这样就可以极大的避免服务进程执行IO操作了。 4). 相比于AOF机制，如果数据集很大，RDB的启动效率会更高。 RDB又存在哪些劣势呢？1). 如果你想保证数据的高可用性，即最大限度的避免数据丢失，那么RDB将不是一个很好的选择。因为系统一旦在定时持久化之前出现宕机现象，此前没有来得及写入磁盘的数据都将丢失。 2). 由于RDB是通过fork子进程来协助完成数据持久化工作的，因此，如果当数据集较大时，可能会导致整个服务器停止服务几百毫秒，甚至是1秒钟。 AOF的优势有哪些呢？1). 该机制可以带来更高的数据安全性，即数据持久性。Redis中提供了3中同步策略，即每秒同步、每修改同步和不同步。事实上，每秒同步也是异步完成的，其效率也是非常高的，所差的是一旦系统出现宕机现象，那么这一秒钟之内修改的数据将会丢失。而每修改同步，我们可以将其视为同步持久化，即每次发生的数据变化都会被立即记录到磁盘中。可以预见，这种方式在效率上是最低的。至于无同步，无需多言，我想大家都能正确的理解它。 2). 由于该机制对日志文件的写入操作采用的是append模式，因此在写入过程中即使出现宕机现象，也不会破坏日志文件中已经存在的内容。然而如果我们本次操作只是写入了一半数据就出现了系统崩溃问题，不用担心，在Redis下一次启动之前，我们可以通过redis-check-aof工具来帮助我们解决数据一致性的问题。 3). 如果日志过大，Redis可以自动启用rewrite机制。即Redis以append模式不断的将修改数据写入到老的磁盘文件中，同时Redis还会创建一个新的文件用于记录此期间有哪些修改命令被执行。因此在进行rewrite切换时可以更好的保证数据安全性。 4). AOF包含一个格式清晰、易于理解的日志文件用于记录所有的修改操作。事实上，我们也可以通过该文件完成数据的重建。 AOF的劣势有哪些呢？1). 对于相同数量的数据集而言，AOF文件通常要大于RDB文件。RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。 2). 根据同步策略的不同，AOF在运行效率上往往会慢于RDB。总之，每秒同步策略的效率是比较高的，同步禁用策略的效率和RDB一样高效。 二者选择的标准，就是看系统是愿意牺牲一些性能，换取更高的缓存一致性（aof），还是愿意写操作频繁的时候，不启用备份来换取更高的性能，待手动运行save的时候，再做备份（rdb）。rdb这个就更有些 eventually consistent的意思了。 RDB和AOF常用配置RDBRedis会将数据集的快照dump到dump.rdb文件中。此外，我们也可以通过配置文件来修改Redis服务器dump快照的频率，在打开6379.conf文件之后，我们搜索save，可以看到下面的配置信息： save 900 1 #在900秒(15分钟)之后，如果至少有1个key发生变化，则dump内存快照。 save 300 10 #在300秒(5分钟)之后，如果至少有10个key发生变化，则dump内存快照。 save 60 10000 #在60秒(1分钟)之后，如果至少有10000个key发生变化，则dump内存快照。 AOF在Redis的配置文件中存在三种同步方式，它们分别是： appendfsync always #每次有数据修改发生时都会写入AOF文件。 appendfsync everysec #每秒钟同步一次，该策略为AOF的缺省策略。 appendfsync no #从不同步。高效但是数据不会被持久化。]]></content>
  </entry>
  <entry>
    <title><![CDATA[MySQL数据库引擎]]></title>
    <url>%2F2018%2F09%2F12%2FMySQL%E6%95%B0%E6%8D%AE%E5%BA%93%E5%BC%95%E6%93%8E%2F</url>
    <content type="text"><![CDATA[数据库引擎 数据库引擎是用于存储、处理和保护数据的核心服务。利用数据库引擎可控制访问权限并快速处理事务，从而满足企业内大多数需要处理大量数据的应用程序的要求。 使用数据库引擎创建用于联机事务处理或联机分析处理数据的关系数据库。这包括创建用于存储数据的表和用于查看、管理和保护数据安全的数据库对象（如索引、视图和存储过程）。 数据库引擎的任务在数据库引擎文档中，各主题的顺序遵循用于实现使用数据库引擎进行数据存储的系统的任务的主要顺序。 设计并创建数据库以保存系统所需的关系或XML文档 实现系统以访问和更改数据库中存储的数据。包括实现网站或使用数据的应用程序，还包括生成使用SQL Server工具和实用工具以使用数据的过程 为单位或客户部署实现的系统 提供日常管理支持以优化数据库的性能 MySQL数据库引擎的类别 你能用的数据库引擎取决于mysql在安装的时候是如何被编译的。要添加一个新的引擎，就必须重新编译MYSQL。在缺省情况下，MYSQL支持三个引擎：ISAM、MYISAM和HEAP。另外两种类型INNODB和BERKLEY（BDB），也常常可以使用。 ISAM ISAM是一个定义明确且历经时间考验的数据表格管理方法，它在设计之时就考虑到数据库被查询的次数要远大于更新的次数。因此，ISAM执行读取操作的速度很快，而且不占用大量的内存和存储资源。ISAM的两个主要不足之处在于，它不支持事务处理，也不能够容错：如果你的硬盘崩溃了，那么数据文件就无法恢复了。如果你正在把ISAM用在关键任务应用程序里，那就必须经常备份你所有的实时数据，通过其复制特性，MYSQL能够支持这样的备份应用程序。 MYISAMMYISAM是MYSQL的ISAM扩展格式和缺省的数据库引擎。除了提供ISAM里所没有的索引和字段管理的功能，MYISAM还使用一种表格锁定的机制，来优化多个并发的读写操作。其代价是你需要经常运行OPTIMIZE TABLE命令，来恢复被更新机制所浪费的空间。MYISAM还有一些有用的扩展，例如用来修复数据库文件的MYISAMCHK工具和用来恢复浪费空间的MYISAMPACK工具。 MYISAM强调了快速读取操作，这可能就是为什么MYSQL受到了WEB开发如此青睐的主要原因：在WEB开发中你所进行的大量数据操作都是读取操作。所以，大多数虚拟主机提供商和INTERNET平台提供商只允许使用MYISAM格式。 HEAPHEAP允许只驻留在内存里的临时表格。驻留在内存里让HEAP要比ISAM和MYISAM都快，但是它所管理的数据是不稳定的，而且如果在关机之前没有进行保存，那么所有的数据都会丢失。在数据行被删除的时候，HEAP也不会浪费大量的空间。HEAP表格在你需要使用SELECT表达式来选择和操控数据的时候非常有用。要记住，在用完表格之后就删除表格。 INNODB和BERKLEYDB INNODB和BERKLEYDB（BDB）数据库引擎都是造就MYSQL灵活性的技术的直接产品，这项技术就是MYSQL++ API。在使用MYSQL的时候，你所面对的每一个挑战几乎都源于ISAM和MYISAM数据库引擎不支持事务处理也不支持外来键。尽管要比ISAM和MYISAM引擎慢很多，但是INNODB和BDB包括了对事务处理和外来键的支持，这两点都是前两个引擎所没有的。如前所述，如果你的设计需要这些特性中的一者或者两者，那你就要被迫使用后两个引擎中的一个了。 MySQL数据库引擎的更改1、查看当前数据库支持的引擎和默认的数据库引擎：show engines;2、更改数据库引擎2.1、更改方式1：修改配置文件my.ini 将my-small.ini另存为my.ini，在[mysqld]后面添加default-storage-engine=InnoDB，重启服务，数据库默认的引擎修改为InnoDB 2.2、更改方式2:在建表的时候指定 1234create table mytbl( id int primary key, name varchar(50) )type=MyISAM; 2.3、更改方式3：建表后更改 alter table mytbl2 type = InnoDB; 3、查看修改结果 1234方式一：show table status from mytest; 方式二：show create table table_name Innodb引擎 Innodb引擎提供了对数据库ACID事务的支持，并且实现了SQL标准的四种隔离级别，关于数据库事务与其隔离级别的内容请见数据库事务与其隔离级别这篇文章。该引擎还提供了行级锁和外键约束，它的设计目标是处理大容量数据库系统，它本身其实就是基于MySQL后台的完整数据库系统，MySQL运行时Innodb会在内存中建立缓冲池，用于缓冲数据和索引。但是该引擎不支持FULLTEXT类型的索引，而且它没有保存表的行数，当SELECT COUNT(*) FROM TABLE时需要扫描全表。当需要使用数据库事务时，该引擎当然是首选。由于锁的粒度更小，写操作不会锁定全表，所以在并发较高时，使用Innodb引擎会提升效率。但是使用行级锁也不是绝对的，如果在执行一个SQL语句时MySQL不能确定要扫描的范围，InnoDB表同样会锁全表。 ACID A 事务的原子性(Atomicity)：指一个事务要么全部执行,要么不执行.也就是说一个事务不可能只执行了一半就停止了.比如你从取款机取钱,这个事务可以分成两个步骤:1划卡,2出钱.不可能划了卡,而钱却没出来.这两步必须同时完成.要么就不完成. C 事务的一致性(Consistency)：指事务的运行并不改变数据库中数据的一致性.例如,完整性约束了a+b=10,一个事务改变了a,那么b也应该随之改变. I 独立性(Isolation）:事务的独立性也有称作隔离性,是指两个以上的事务不会出现交错执行的状态.因为这样可能会导致数据不一致. D 持久性(Durability）:事务的持久性是指事务执行成功以后,该事务所对数据库所作的更改便是持久的保存在数据库之中，不会无缘无故的回滚. MyISAM引擎 MyIASM是MySQL默认的引擎，但是它没有提供对数据库事务的支持，也不支持行级锁和外键，因此当INSERT(插入)或UPDATE(更新)数据时即写操作需要锁定整个表，效率便会低一些。不过和Innodb不同，MyIASM中存储了表的行数，于是SELECT COUNT(*) FROM TABLE时只需要直接读取已经保存好的值而不需要进行全表扫描。如果表的读操作远远多于写操作且不需要数据库事务的支持，那么MyIASM也是很好的选择。 两种引擎的选择 大尺寸的数据集趋向于选择InnoDB引擎，因为它支持事务处理和故障恢复。数据库的大小决定了故障恢复的时间长短，InnoDB可以利用事务日志进行数据恢复，这会比较快。主键查询在InnoDB引擎下也会相当快，不过需要注意的是如果主键太长也会导致性能问题，关于这个问题我会在下文中讲到。大批的INSERT语句(在每个INSERT语句中写入多行，批量插入)在MyISAM下会快一些，但是UPDATE语句在InnoDB下则会更快一些，尤其是在并发量大的时候。 MyISAM的引擎的索引结构 MyISAM引擎的索引结构为B+Tree，其中B+Tree的数据域存储的内容为实际数据的地址，也就是说它的索引和实际的数据是分开的，只不过是用索引指向了实际的数据，这种索引就是所谓的非聚集索引。 Innodb引擎的索引结构与MyISAM引擎的索引结构同样也是B+Tree，但是Innodb的索引文件本身就是数据文件，即B+Tree的数据域存储的就是实际的数据，这种索引就是聚集索引。这个索引的key就是数据表的主键，因此InnoDB表数据文件本身就是主索引。并且和MyISAM不同，InnoDB的辅助索引数据域存储的也是相应记录主键的值而不是地址，所以当以辅助索引查找时，会先根据辅助索引找到主键，再根据主键索引找到实际的数据。所以Innodb不建议使用过长的主键，否则会使辅助索引变得过大。建议使用自增的字段作为主键，这样B+Tree的每一个结点都会被顺序的填满，而不会频繁的分裂调整，会有效的提升插入数据的效率。 两者区别 第一个重大区别是InnoDB的数据文件本身就是索引文件。从上文知道，MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。 MySQL四种事务的隔离级别 Serializable 串行化，一个事务一个事务的执行 Repeatable read 可重复读，无论其他事务是否修改并提交了数据，在这个事务中看到的数据值始终不受其他事务影响 Read committed 读取已提交，其他事务提交了对数据的修改后，本事务就能读取到修改后的数据值 Read uncommitted 读取未提交，其他事务只要修改了数据，即使未提交，本事务也能看到修改后的数据值。MySQL数据库默认使用可重复读（ Repeatable read），而使用乐观锁的时候，如果一个事务修改了库存并提交了事务，那其他的事务应该可以读取到修改后的数据值，所以不能使用可重复读的隔离级别，应该修改为读取已提交Read committed。 修改方法]]></content>
  </entry>
  <entry>
    <title><![CDATA[MySQL]]></title>
    <url>%2F2018%2F09%2F11%2FMySQL%2F</url>
    <content type="text"><![CDATA[MySQL简介MySQL是一个关系型数据库管理系统，由瑞典MySQL AB公司开发，目前属于Oracle公司。MySQL是一种关联数据库管理系统，关联数据库将数据保存在不同的表中，而不是将所有数据放在一个大仓库内，这样就增加了速度并提高了灵活性。 Mysql是开源的，所以你不需要支付额外的费用。 Mysql支持大型的数据库。可以处理拥有上千万条记录的大型数据库。 MySQL使用标准的SQL数据语言形式。 Mysql可以允许于多个系统上，并且支持多种语言。这些编程语言包括C、C++、Python、Java、Perl、PHP、Eiffel、Ruby和Tcl等。 Mysql对PHP有很好的支持，PHP是目前最流行的Web开发语言。 MySQL支持大型数据库，支持5000万条记录的数据仓库，32位系统表文件最大可支持4GB，64位系统支持最大的表文件为8TB。 Mysql是可以定制的，采用了GPL协议，你可以修改源码来开发自己的Mysql系统。 MySQL安装关于mysql的安装请参考链接:http://www.runoob.com/mysql/mysql-install.html MySQL操作登陆12345mysql -D 所选择的数据库名 -h 主机名 -u 用户名 -p 密码mysql&gt; exit # 退出 使用 “quit;” 或 “\q;” 一样的效果mysql&gt; status; # 显示当前mysql的version的各种信息mysql&gt; select version(); # 显示当前mysql的version信息mysql&gt; show global variables like 'port'; # 查看MySQL端口号 显示数据库1SHOW DATABASES; 默认数据库：mysql - 用户权限相关数据test - 用于用户测试数据information_schema - MySQL本身架构相关数据 创建数据库12345# utf-8CREATE DATABASE 数据库名称 DEFAULT CHARSET utf8 COLLATE utf8_general_ci; # gbkCREATE DATABASE 数据库名称 DEFAULT CHARACTER SET gbk COLLATE gbk_chinese_ci; 数据库的查询操作1.查询所有字段 123select * from 表名;例：select * from students; 2.查询指定字段 123select 列1,列2,... from 表名;例:select name from students; 3.使用as给字段取别名 1select id as 序号, name as 名字, gender as 性别 from students; 4.可以通过 as 给表起别名 12345678-- 如果是单表查询 可以省略表明select id, name, gender from students;-- 表名.字段名select students.id,students.name,students.gender from students;-- 可以通过 as 给表起别名 select s.id,s.name,s.gender from students as s; 5.在select后面列前使用distinct可以消除重复的行 123select distinct 列1,... from 表名;例：select distinct gender from students; 条件查询数据库使用where子句对表中的数据筛选，结果为true的行会出现在结果集中： 123select * from 表名 where 条件;例：select * from students where id=1; where后面支持多种运算符，进行条件的处理： 比较运算符 逻辑运算符 模糊查询 范围查询 空判断1.比较运算符 12345678例1：查询编号大于3的学生select * from students where id &gt; 3;例2：查询编号不大于4的学生select * from students where id &lt;= 4;例3：查询姓名不是“黄蓉”的学生select * from students where name != '黄蓉';例4：查询没被删除的学生select * from students where is_delete=0; 2.逻辑运算符or 、and、not1234例5：查询编号大于3的女同学select * from students where id &gt; 3 and gender=0;例6：查询编号小于4或没被删除的学生select * from students where id &lt; 4 or is_delete=0; 3.模糊查询：like %表示任意多个任意字符 _表示一个任意字符 123456例7：查询姓黄的学生select * from students where name like &apos;黄%&apos;;例8：查询姓黄并且“名”是一个字的学生select * from students where name like &apos;黄_&apos;;例9：查询姓黄或叫靖的学生select * from students where name like &apos;黄%&apos; or name like &apos;%靖&apos;; 4.范围查询in表示在一个非连续的范围内；between … and …表示在一个连续的范围内； 123456例10：查询编号是1或3或8的学生select * from students where id in(1,3,8);例11：查询编号为3至8的学生select * from students where id between 3 and 8;例12：查询编号是3至8的男生select * from students where (id between 3 and 8) and gender=1; 5.空判断判空is null；判非空is not null； 123456例13：查询没有填写身高的学生select * from students where height is null;例14：查询填写了身高的学生select * from students where height is not null;例15：查询填写了身高的男生select * from students where height is not null and gender=1; 6.优先级 优先级由高到低的顺序为：小括号，not，比较运算符，逻辑运算符 and比or先运算，如果同时出现并希望先算or，需要结合()使用 排序语法： 1select * from 表名 order by 列1 asc|desc [,列2 asc|desc,...] 说明： 将行数据按照列1进行排序，如果某些行列1的值相同时，则按照列2排序，以此类推 默认按照列值从小到大排列（asc） asc从小到大排列，即升序 desc从大到小排序，即降序 123456例1：查询未删除男生信息，按学号降序select * from students where gender=1 and is_delete=0 order by id desc;例2：查询未删除学生信息，按名称升序select * from students where is_delete=0 order by name;例3：显示所有的学生信息，先按照年龄从大--&gt;小排序，当年龄相同时 按照身高从高--&gt;矮排序select * from students order by age desc,height desc; 聚合函数总数：count(*)表示计算总行数，括号中写星与列名，结果是相同的最大值：max(列)表示求此列的最大值最小值：min（列）表示求此列的最小值平均值：avg(列)表示求此列的平均值求和：sum（列）表示求此列的和 12345678910111213例1：查询学生总数select count(*) from students;例2：查询女生的编号最大值select max(id) from students where gender=2;例3：查询未删除的学生最小编号select min(id) from students where is_delete=0;例4：查询男生的总年龄select sum(age) from students where gender=1;-- 平均年龄select sum(age)/count(*) from students where gender=1;例5：查询未删除女生的编号平均值select avg(id) from students where is_delete=0 and gender=2; 分组1.group by的含义:将查询结果按照1个或多个字段进行分组，字段值相同的为一组。2.group by可用于单个字段分组，也可用于多个字段分组。 1234567891011121314151617181920212223242526272829select * from students;+----+-----------+------+--------+--------+--------+-----------+| id | name | age | height | gender | cls_id | is_delete |+----+-----------+------+--------+--------+--------+-----------+| 1 | 小明 | 18 | 180.00 | 女 | 1 | || 2 | 小月月 | 18 | 180.00 | 女 | 2 |  || 3 | 彭于晏 | 29 | 185.00 | 男 | 1 | || 4 | 刘德华 | 59 | 175.00 | 男 | 2 |  || 5 | 黄蓉 | 38 | 160.00 | 女 | 1 | || 6 | 凤姐 | 28 | 150.00 | 保密 | 2 |  || 7 | 王祖贤 | 18 | 172.00 | 女 | 1 |  || 8 | 周杰伦 | 36 | NULL | 男 | 1 | || 9 | 程坤 | 27 | 181.00 | 男 | 2 | || 10 | 刘亦菲 | 25 | 166.00 | 女 | 2 | || 11 | 金星 | 33 | 162.00 | 中性 | 3 |  || 12 | 静香 | 12 | 180.00 | 女 | 4 | || 13 | 周杰 | 34 | 176.00 | 女 | 5 | || 14 | 郭靖 | 12 | 170.00 | 男 | 4 | |+----+-----------+------+--------+--------+--------+-----------+select gender from students group by gender;+--------+| gender |+--------+| 男 || 女 || 中性 || 保密 |+--------+ 根据gender字段来分组，gender字段的全部值有4个’男’,’女’,’中性’,’保密’，所以分为了4组 当group by单独使用时，只显示出每组的第一条记录, 所以group by单独使用时的实际意义不大。2.group by + group_concat() group_concat(字段名)可以作为一个输出字段来使用，表示分组之后，根据分组结果，使用group_concat()来放置每一组的某字段的值的集合 123456789101112131415161718192021222324252627282930select gender from students group by gender;+--------+| gender |+--------+| 男 || 女 || 中性 || 保密 |+--------+select gender,group_concat(name) from students group by gender;+--------+-----------------------------------------------------------+| gender | group_concat(name) |+--------+-----------------------------------------------------------+| 男 | 彭于晏,刘德华,周杰伦,程坤,郭靖 || 女 | 小明,小月月,黄蓉,王祖贤,刘亦菲,静香,周杰 || 中性 | 金星 || 保密 | 凤姐 |+--------+-----------------------------------------------------------+select gender,group_concat(id) from students group by gender;+--------+------------------+| gender | group_concat(id) |+--------+------------------+| 男 | 3,4,8,9,14 || 女 | 1,2,5,7,10,12,13 || 中性 | 11 || 保密 | 6 |+--------+------------------+ 2.group by + 集合函数 通过group_concat()的启发，我们既然可以统计出每个分组的某字段的值的集合，那么我们也可以通过集合函数来对这个值的集合做一些操作。 1234567891011121314151617181920212223242526272829303132select gender,group_concat(age) from students group by gender;+--------+----------------------+| gender | group_concat(age) |+--------+----------------------+| 男 | 29,59,36,27,12 || 女 | 18,18,38,18,25,12,34 || 中性 | 33 || 保密 | 28 |+--------+----------------------+分别统计性别为男/女的人年龄平均值select gender,avg(age) from students group by gender;+--------+----------+| gender | avg(age) |+--------+----------+| 男 | 32.6000 || 女 | 23.2857 || 中性 | 33.0000 || 保密 | 28.0000 |+--------+----------+分别统计性别为男/女的人的个数select gender,count(*) from students group by gender;+--------+----------+| gender | count(*) |+--------+----------+| 男 | 5 || 女 | 7 || 中性 | 1 || 保密 | 1 |+--------+----------+ 3.group by + having having 条件表达式：用来分组查询后指定一些条件来输出查询结果 having作用和where一样，但having只能用于group by 1234567select gender,count(*) from students group by gender having count(*)&gt;2;+--------+----------+| gender | count(*) |+--------+----------+| 男 | 5 || 女 | 7 |+--------+----------+ 5.group by + with rollup with rollup的作用是：在最后新增一行，来记录当前列里所有记录的总和. 12345678910111213141516171819202122select gender,count(*) from students group by gender with rollup;+--------+----------+| gender | count(*) |+--------+----------+| 男 | 5 || 女 | 7 || 中性 | 1 || 保密 | 1 || NULL | 14 |+--------+----------+select gender,group_concat(age) from students group by gender with rollup;+--------+-------------------------------------------+| gender | group_concat(age) |+--------+-------------------------------------------+| 男 | 29,59,36,27,12 || 女 | 18,18,38,18,25,12,34 || 中性 | 33 || 保密 | 28 || NULL | 29,59,36,27,12,18,18,38,18,25,12,34,33,28 |+--------+-------------------------------------------+ 分页语法：select * from 表名 limit start,count说明：从start开始，获取count条数据 12例1：查询前3行男生信息select * from students where gender=1 limit 0,3; 连接查询MySQL支持三种类型的连接查询： 内连接查询：查询的结果为两个表匹配到的数据 右连接查询：查询的结果为两个表匹配到的数据，右表特有的数据，对于左表中不存在的数据使用null填充 左连接查询：查询的结果为两个表匹配到的数据，左表特有的数据，对于右表中不存在的数据使用null填充语法：select * from 表1 inner或left或right join 表2 on 表1.列 = 表2.列 12345678例1：使用内连接查询班级表与学生表select * from students inner join classes on students.cls_id = classes.id;例2：使用左连接查询班级表与学生表select * from students as s left join classes as c on s.cls_id = c.id;例3：使用右连接查询班级表与学生表select * from students as s right join classes as c on s.cls_id = c.id;例4：查询学生姓名及班级名称select s.name,c.name from students as s inner join classes as c on s.cls_id = c.id; 自关联用一个例子来说明：（省市区） 123456789定义表areas，结构如下idatitlepid说明：1.因为省没有所属的省份，所以可以填写为null2.城市所属的省份pid，填写省所对应的编号id2.这就是自关联，表中的某一列，关联了这个表中的另外一列，但是它们的业务逻辑含义是不一样的，城市信息的pid引用的是省信息的id4.在这个表中，结构不变，可以添加区县、乡镇街道、村社区等信息 创建areas表的语句如下： 12345create table areas( aid int primary key, atitle varchar(20), pid int); 从sql文件中导入数据：source areas.sql; 12345678910查询一共有多少个省select count(*) from areas where pid is null;例1：查询省的名称为“山西省”的所有城市select city.* from areas as cityinner join areas as province on city.pid=province.aidwhere province.atitle=&apos;山西省&apos;;例2：查询市的名称为“广州市”的所有区县select dis.* from areas as disinner join areas as city on city.aid=dis.pidwhere city.atitle=&apos;广州市&apos;; 子查询子查询：在一个 select 语句中,嵌入了另外一个 select 语句, 那么被嵌入的 select 语句称之为子查询语句主查询：主要查询的对象,第一条 select 语句主查询和子查询的关系：1.子查询是嵌入到主查询中2.子查询是辅助主查询的,要么充当条件,要么充当数据源3.子查询是可以独立存在的语句,是一条完整的 select 语句子查询的分类： 标量子查询: 子查询返回的结果是一个数据(一行一列) 列子查询: 返回的结果是一列(一列多行) 行子查询: 返回的结果是一行(一行多列)标量子查询： 123查询班级学生平均年龄查询大于平均年龄的学生select * from students where age &gt; (select avg(age) from students); 列级子查询： 12查询还有学生在班的所有班级名字select name from classes where id in (select cls_id from students); 行级子查询： 12查找班级年龄最大,身高最高的学生select * from students where (height,age) = (select max(height),max(age) from students); 子查询中特定关键字使用：in 范围：格式: 主查询 where 条件 in (列子查询)完整查询语句的执行顺序： 123456select distinct *from 表名where ....group by ... having ...order by ...limit start,count 执行顺序为： from 表名 where …. group by … select distinct * having … order by … limit start,count 数据的增删改查1234567891011121314查看所有数据库show databases;使用数据库use 数据库名;查看当前使用的数据库select database();创建数据库create database 数据库名 charset=utf8;例：create database python charset=utf8;删除数据库drop database 数据库名;例：drop database python; 数据表的操作123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051查看当前数据库中所有表show tables;查看表结构desc 表名;创建表：auto_increment表示自动增长CREATE TABLE table_name( column1 datatype contrai, column2 datatype, column3 datatype, ..... columnN datatype, PRIMARY KEY(one or more columns));例：创建班级表create table classes( id int unsigned auto_increment primary key not null, name varchar(10));例：创建学生表create table students( id int unsigned primary key auto_increment not null, name varchar(20) default &apos;&apos;, age tinyint unsigned default 0, height decimal(5,2), gender enum(&apos;男&apos;,&apos;女&apos;,&apos;人妖&apos;,&apos;保密&apos;), cls_id int unsigned default 0)修改表-添加字段alter table 表名 add 列名 类型;例：alter table students add birthday datetime；修改表-修改字段：重命名版alter table 表名 change 原名 新名 类型及约束;例：alter table students change birthday birth datetime not null;修改表-修改字段：不重命名版alter table 表名 modify 列名 类型及约束;例：alter table students modify birth date not null;修改表-删除字段alter table 表名 drop 列名;例：alter table students drop birthday;删除表drop table 表名;例：drop table students;查看表的创建语句show create table 表名;例：show create table classes; 数据的增删改查 查询： 12345678查询所有列select * from 表名;例：select * from classes;查询指定列select 列1,列2,... from 表名;例：select id,name from classes; 增加格式:INSERT [INTO] tb_name [(col_name,…)] {VALUES | VALUE} ({expr | DEFAULT},…),(…),…说明：主键列是自动增长，但是在全列插入时需要占位，通常使用0或者 default 或者 null 来占位，插入成功后以实际数据为准。 123456789101112131415全列插入：值的顺序与表中字段的顺序对应。insert into 表名 values(...)例：insert into students values(0,’郭靖‘,1,&apos;蒙古&apos;,&apos;2016-1-2&apos;);部分列插入：值的顺序与给出的列顺序对应insert into 表名(列1,...) values(值1,...)例：insert into students(name,hometown,birthday) values(&apos;黄蓉&apos;,&apos;桃花岛&apos;,&apos;2016-3-2&apos;);全列多行插入：值的顺序与给出的列顺序对应insert into 表名 values(...),(...)...;例：insert into classes values(0,&apos;python1&apos;),(0,&apos;python2&apos;);insert into 表名(列1,...) values(值1,...),(值1,...)...;例：insert into students(name) values(&apos;杨康&apos;),(&apos;杨过&apos;),(&apos;小龙女&apos;); 修改格式: UPDATE tbname SET col1={expr1|DEFAULT} [,col2={expr2|default}]…[where 条件判断] 123update 表名 set 列1=值1,列2=值2... where 条件例：update students set gender=0,hometown=&apos;北京&apos; where id=5; 删除DELETE FROM tbname [where 条件判断] 12345delete from 表名 where 条件例：delete from students where id=5;逻辑删除，本质就是修改操作update students set isdelete=1 where id=1; 数据库备份与恢复备份123mysqldump –uroot –p 数据库名 &gt; python.sql;# 按提示输入mysql的密码 恢复12345连接mysql，创建新的数据库退出连接，执行如下命令mysql -uroot –p 新数据库名 &lt; python.sql# 根据提示输入mysql密码 MySQL与数据库的交互python操作数据库的步骤：1.引入模块from pymysql import *2.Connection 对象用于建立与数据库的连接创建对象：调用connect()方法conn=connect(参数列表) 参数host：连接的mysql主机，如果本机是’localhost’ 参数port：连接的mysql主机的端口，默认是3306 参数database：数据库的名称 参数user：连接的用户名 参数password：连接的密码 参数charset：通信采用的编码方式，推荐使用utf8对象的方法： close()关闭连接 commit()提交 cursor()返回Cursor对象，用于执行sql语句并获得结果3.cursor对象 用于执行sql语句，使用频度最高的语句为select、insert、update、delete 获取Cursor对象：调用Connection对象的cursor()方法cs1=conn.cursor()对象的方法： close()关闭 execute(operation [, parameters ])执行语句，返回受影响的行数，主要用于执行insert、update、delete语句，也可以执行create、alter、drop等语句 fetchone()执行查询语句时，获取查询结果集的第一个行数据，返回一个元组 fetchall()执行查询时，获取结果集的所有行，一行构成一个元组，再将这些元组装入一个元组返回对象的属性： rowcount只读属性，表示最近一次execute()执行后受影响的行数 connection获得当前连接对象实例：1.增删改 12345678910111213141516171819202122232425262728293031from pymysql import *def main(): # 创建Connection连接 conn = connect(host=&apos;localhost&apos;,port=3306,database=&apos;jing_dong&apos;,user=&apos;root&apos;,password=&apos;mysql&apos;,charset=&apos;utf8&apos;) # 获得Cursor对象 cs1 = conn.cursor() # 执行insert语句，并返回受影响的行数：添加一条数据 # 增加 count = cs1.execute(&apos;insert into goods_cates(name) values(&quot;硬盘&quot;)&apos;) #打印受影响的行数 print(count) count = cs1.execute(&apos;insert into goods_cates(name) values(&quot;光盘&quot;)&apos;) print(count) # # 更新 # count = cs1.execute(&apos;update goods_cates set name=&quot;机械硬盘&quot; where name=&quot;硬盘&quot;&apos;) # # 删除 # count = cs1.execute(&apos;delete from goods_cates where id=6&apos;) # 提交之前的操作，如果之前已经之执行过多次的execute，那么就都进行提交 conn.commit() # 关闭Cursor对象 cs1.close() # 关闭Connection对象 conn.close()if __name__ == &apos;__main__&apos;: main() 2.查询一行数据 12345678910111213141516171819202122232425from pymysql import *def main(): # 创建Connection连接 conn = connect(host=&apos;localhost&apos;,port=3306,user=&apos;root&apos;,password=&apos;mysql&apos;,database=&apos;jing_dong&apos;,charset=&apos;utf8&apos;) # 获得Cursor对象 cs1 = conn.cursor() # 执行select语句，并返回受影响的行数：查询一条数据 count = cs1.execute(&apos;select id,name from goods where id&gt;=4&apos;) # 打印受影响的行数 print(&quot;查询到%d条数据:&quot; % count) for i in range(count): # 获取查询的结果 result = cs1.fetchone() # 打印查询的结果 print(result) # 获取查询的结果 # 关闭Cursor对象 cs1.close() conn.close()if __name__ == &apos;__main__&apos;: main() 3.查询多行数据 12345678910111213141516171819202122232425262728from pymysql import *def main(): # 创建Connection连接 conn = connect(host=&apos;localhost&apos;,port=3306,user=&apos;root&apos;,password=&apos;mysql&apos;,database=&apos;jing_dong&apos;,charset=&apos;utf8&apos;) # 获得Cursor对象 cs1 = conn.cursor() # 执行select语句，并返回受影响的行数：查询一条数据 count = cs1.execute(&apos;select id,name from goods where id&gt;=4&apos;) # 打印受影响的行数 print(&quot;查询到%d条数据:&quot; % count) # for i in range(count): # # 获取查询的结果 # result = cs1.fetchone() # # 打印查询的结果 # print(result) # # 获取查询的结果 result = cs1.fetchall() print(result) # 关闭Cursor对象 cs1.close() conn.close()if __name__ == &apos;__main__&apos;: main() 参数化 sql语句的参数化，可以有效防止sql注入 注意：此处不同于python的字符串格式化，全部使用%s占位 123456789101112131415161718192021222324252627282930313233343536373839404142from pymysql import *def main(): find_name = input(&quot;请输入物品名称：&quot;) # 创建Connection连接 conn = connect(host=&apos;localhost&apos;,port=3306,user=&apos;root&apos;,password=&apos;mysql&apos;,database=&apos;jing_dong&apos;,charset=&apos;utf8&apos;) # 获得Cursor对象 cs1 = conn.cursor() # # 非安全的方式 # # 输入 &quot; or 1=1 or &quot; (双引号也要输入) # sql = &apos;select * from goods where name=&quot;%s&quot;&apos; % find_name # print(&quot;&quot;&quot;sql===&gt;%s&lt;====&quot;&quot;&quot; % sql) # # 执行select语句，并返回受影响的行数：查询所有数据 # count = cs1.execute(sql) # 安全的方式 # 构造参数列表 params = [find_name] # 执行select语句，并返回受影响的行数：查询所有数据 count = cs1.execute(&apos;select * from goods where name=%s&apos;, params) # 注意： # 如果要是有多个参数，需要进行参数化 # 那么params = [数值1, 数值2....]，此时sql语句中有多个%s即可 # 打印受影响的行数 print(count) # 获取查询的结果 # result = cs1.fetchone() result = cs1.fetchall() # 打印查询的结果 print(result) # 关闭Cursor对象 cs1.close() # 关闭Connection对象 conn.close()if __name__ == &apos;__main__&apos;: main() MySQL高级视图1.视图的含义：通俗的讲，视图就是一条SELECT语句执行后返回的结果集。所以我们在创建视图的时候，主要的工作就落在创建这条SQL查询语句上。视图是对若干张基本表的引用，一张虚表，查询语句执行的结果，不存储具体的数据（基本表数据发生了改变，视图也会跟着改变）；方便操作，特别是查询操作，减少复杂的SQL语句，增强可读性； 12345678910定义视图：建议以v_开头create view 视图名称 as select语句; 查看视图：查看表会将所有的视图也列出来 show tables; 使用视图：视图的用途就是查询 select * from v_stu_score; 删除视图： drop view 视图名称;例：drop view v_stu_sco; 2.视图的作用： 提高了重用性，就像一个函数 对数据库重构，却不影响程序的运行 提高了安全性能，可以对不同的用户 让数据更加清晰 事务1.概念所谓事务,它是一个操作序列，这些操作要么都执行，要么都不执行，它是一个不可分割的工作单位。2.事务的四大特性 原子性(Atomicity)一个事务必须被视为一个不可分割的最小工作单元，整个事务中的所有操作要么全部提交成功，要么全部失败回滚，对于一个事务来说，不可能只执行其中的一部分操作，这就是事务的原子性。 一致性(Consistency)数据库总是从一个一致性的状态转换到另一个一致性的状态。（在前面的例子中，一致性确保了，即使在执行第三、四条语句之间时系统崩溃，支票账户中也不会损失200美元，因为事务最终没有提交，所以事务中所做的修改也不会保存到数据库中。） 隔离性(Isolation)通常来说，一个事务所做的修改在最终提交以前，对其他事务是不可见的。（在前面的例子中，当执行完第三条语句、第四条语句还未开始时，此时有另外的一个账户汇总程序开始运行，则其看到支票帐户的余额并没有被减去200美元。） 持久性(Durability)一旦事务提交，则其所做的修改会永久保存到数据库。（此时即使系统崩溃，修改的数据也不会丢失。）3.事务的命令表的引擎类型必须是innodb类型才可以使用事务，这是mysql表的默认引擎。 12345678开启事务后执行修改命令，变更会维护到本地缓存中，而不维护到物理表中：begin;或者start transaction;提交事务，命令如下：将缓存中的数据变更维护到物理表中commit;回滚事务，命令如下：放弃缓存中变更的数据rollback; 注意： 修改数据的命令会自动的触发事务，包括insert、update、delete 而在SQL语句中有手动开启事务的原因是：可以进行多次数据的修改，如果成功一起成功，否则一起会滚到之前的数据 索引1.索引是什么索引是一种特殊的文件(InnoDB数据表上的索引是表空间的一个组成部分)，它们包含着对数据表里所有记录的引用指针。更通俗的说，数据库索引好比是一本书前面的目录，能加快数据库的查询速度。2.索引目的索引的目的在于提高查询效率，可以类比字典，如果要查“mysql”这个单词，我们肯定需要定位到m字母，然后从下往下找到y字母，再找到剩下的sql。如果没有索引，那么你可能需要把所有单词看一遍才能找到你想要的，如果我想找到m开头的单词呢？或者ze开头的单词呢？是不是觉得如果没有索引，这个事情根本无法完成？3.索引的原理除了词典，生活中随处可见索引的例子，如火车站的车次表、图书的目录等。它们的原理都是一样的，通过不断的缩小想要获得数据的范围来筛选出最终想要的结果，同时把随机的事件变成顺序的事件，也就是我们总是通过同一种查找方式来锁定数据。 数据库也是一样，但显然要复杂许多，因为不仅面临着等值查询，还有范围查询(&gt;、&lt;、between、in)、模糊查询(like)、并集查询(or)等等。数据库应该选择怎么样的方式来应对所有的问题呢？我们回想字典的例子，能不能把数据分成段，然后分段查询呢？最简单的如果1000条数据，1到100分成第一段，101到200分成第二段，201到300分成第三段……这样查第250条数据，只要找第三段就可以了，一下子去除了90%的无效数据。 4.查看索引show index from 表名;5.创建索引 如果指定字段是字符串，需要指定长度，建议长度与定义字段时的长度一致 字段类型如果不是字符串，可以不填写长度部分create index 索引名称 on 表名(字段名称(长度))6.删除索引drop index 索引名称 on 表名;7.注意要注意的是，建立太多的索引将会影响更新和插入的速度，因为它需要同样更新每个索引文件。对于一个经常需要更新和插入的表格，就没有必要为一个很少使用的where字句单独建立索引了，对于比较小的表，排序的开销不会很大，也没有必要建立另外的索引。建立索引会占用磁盘空间。 账户管理 在生产环境下操作数据库时，绝对不可以使用root账户连接，而是创建特定的账户，授予这个账户特定的操作权限，然后连接进行操作，主要的操作就是数据的crud MySQL账户体系：根据账户所具有的权限的不同，MySQL的账户可以分为以下几种：1.服务实例级账号：，启动了一个mysqld，即为一个数据库实例；如果某用户如root,拥有服务实例级分配的权限，那么该账号就可以删除所有的数据库、连同这些库中的表2.数据库级别账号：对特定数据库执行增删改查的所有操作3.数据表级别账号：对特定表执行增删改查等所有操作4.字段级别的权限：对某些表的特定字段进行操作5.存储程序级别的账号：对存储程序进行增删改查的操作 账户的操作主要包括创建账户、删除账户、修改密码、授权权限等 注意：1.进行账户操作时，需要使用root账户登录，这个账户拥有最高的实例级权限2.通常都使用数据库级操作权限 授予权限1.查看所有用户 所有用户及权限信息存储在mysql数据库的user表中 查看user表的结构desc user;说明：1.Host表示允许访问的主机2.User表示用户名3.authentication_string表示密码，为加密后的值查看所有用户：select host,user,authentication_string from user;2.创建用户 12345需要使用实例级账户登录后操作，以root为例常用权限主要包括：create、alter、drop、insert、update、delete、select如果分配所有权限，可以使用all privileges创建账户&amp;授权：grant 权限列表 on 数据库 to &apos;用户名&apos;@&apos;访问主机&apos; identified by &apos;密码&apos;; 实例：创建一个laowang的账号，密码为123456，只能通过本地访问, 并且只能对jing_dong数据库中的所有表进行读操作1234567891011121314151617step1：使用root登录mysql -uroot -p回车后写密码，然后回车step2：创建账户并授予所有权限grant select on jing_dong.* to &apos;laowang&apos;@&apos;localhost&apos; identified by &apos;123456&apos;;说明： - 可以操作python数据库的所有表，方式为:jing_dong.* - 访问主机通常使用 百分号% 表示此账户可以使用任何ip的主机登录访问此数据库 - 访问主机可以设置成 localhost或具体的ip，表示只允许本机或特定主机访问 - 查看用户有哪些权限 show grants for laowang@localhost; step3：退出root的登录 quit step4：使用laowang账户登录 mysql -ulaowang -p回车后写密码，然后回车 示例2： 创建一个laoli的账号，密码为12345678，可以任意电脑进行链接访问, 并且对jing_dong数据库中的所有表拥有所有权限 1grant all privileges on jing_dong.* to &quot;laoli&quot;@&quot;%&quot; identified by &quot;12345678&quot; 2.账户操作 修改权限grant 权限名称 on 数据库 to 账户@主机 with grant option; 修改密码使用root登录，修改mysql数据库的user表： 使用password()函数进行密码加密 123update user set authentication_string=password(&apos;新密码&apos;) where user=&apos;用户名&apos;;例：update user set authentication_string=password(&apos;123&apos;) where user=&apos;laowang&apos;; 注意修改完成后需要刷新权限 1刷新权限：flush privileges 远程登录（危险慎用）修改 /etc/mysql/mysql.conf.d/mysqld.cnf 文件 1vim /etc/mysql/mysql.conf.d/mysqld.cnf 然后重启msyql 1service mysql restart 在另一台Ubuntu中测试连接 1234567891011121314151617如果依然连不上，可能原因：1) 网络不通通过 ping xxx.xxx.xx.xxx可以发现网络是否正常2)查看数据库是否配置了bind_address参数本地登录数据库查看my.cnf文件和数据库当前参数show variables like &apos;bind_address&apos;;如果设置了bind_address=127.0.0.1 那么只能本地登录3)查看数据库是否设置了skip_networking参数如果设置了该参数，那么只能本地登录mysql数据库4)端口指定是否正确 删除用户1.语法1：使用root登录 123drop user &apos;用户名&apos;@&apos;主机&apos;;例：drop user &apos;laowang&apos;@&apos;%&apos;; 2.使用root登录，删除mysql数据库的user表中数据 123456delete from user where user=&apos;用户名&apos;;例：delete from user where user=&apos;laowang&apos;;-- 操作结束之后需要刷新权限flush privileges 3.忘记 root 账户密码怎么办? 到时候再来查http://blog.csdn.net/lxpbs8851/article/details/10895085]]></content>
  </entry>
  <entry>
    <title><![CDATA[itsdangerous]]></title>
    <url>%2F2018%2F09%2F11%2Fitsdangerous%2F</url>
    <content type="text"><![CDATA[itsdangerous介绍有时候你想向不可信的环境发送一些数据，但如何安全完成这个任务呢？解决的方法就是签名。使用只有你自己知道的密钥，来加密签名你的数据，并把加密后的数据发给别人。当你取回数据时，你就可以确保没人篡改过这份数据。诚然，接收者可以破译内容，来看看你的包裹里有什么，但他们没办法修改你的内容，除非他们也有你的密钥。所以只要你保管好你的密钥，并且密钥足够复杂，一切就OK了。itsdangerous内部默认使用了HMAC和SHA1来签名，基于 Django 签名模块。它也支持JSON Web 签名 (JWS)。这个库采用BSD协议，由Armin Ronacher编写，而大部分设计与实现的版权归Simon Willison和其他的把这个库变为现实的Django爱好者们。itsdangerous中dumps和loads： json，pickle, itsdangerous中的loads、dumps 的对比分析1.json中的json.dumps和json.loads: json.dumps(): 将一个Python数据类型进行json格式的编码解析(dict转成str) json.loads():将json格式的基于字典的字符串转换成Python数据类型（str转成dict） 扩展：json.loads和json.load，json.dumps和json.dump的区别 json.dump是将python数据保存成json。主要配合json.load来使用。 json.dump(x,f)，x是对象，f是文件对象，将json数据写入到f文本文件当中。 json.load是读取json数据 。主要配合json.dump来使用. 2. pickle中的pickle.dumps和pickle.loads： pickle.dumps():将obj对象序列化并返回一个bytes对象(某一个数据类型转成bytes). pickle.loads():将bytes反序列化并返回一个对象(bytes转成之前的数据类型). 扩展：pickle.loads和pickle.load，pickle.dumps和pickle.dump的区别pickle.dump()方法将obj对象序列化为字节（bytes）写入到file文件中pickle.load()从一个对象文件中读取序列化数据，将其反序列化之后返回一个对象. 3.json-pickle-itsdangerous对比总结:1-pickle不是用于多种语言间的数据传输，它仅作为python对象的持久化，只针对python的数据类型；而json可以支持更多语言的序列化和反序列化，在python中序列化一个自定义的类对象时，会抛出一个 TypeError;2-json的序列化输出是文本对象是str类型，而pickle序列化的输出是二进制字节-bytes 3-json可读性优于pickle。 4-itsdangerous也提供了一个与json或pickle类似的序列化接口。（它内部默认使用simplejson，但是可以通过子类进行修改） 5-pickle:就是将python数据转成原始的二进制数据； itsdangerous:就是通过密钥secret-key进行加密处理。多用于生成token。 4.jsonify和json.dumps()sonify的作用实际上就是将我们传入的json形式数据序列化成为json字符串，作为响应的body，并且设置响应的Content-Type为application/json，构造出响应返回至客户端。jsonify的部分源码如下： jsonify将dict类型转变为json对象。json.dumps只是将dict类型转化为str类型，并非一个json对象。jsonify其实也是用dumps方法转换成了json格式的字符串，但是jsonify会根据http协议的body进行格式重新编排。而json.dumps只是单纯的将dict类型转化为str类型，可以直接return json.dumps(data)。]]></content>
  </entry>
  <entry>
    <title><![CDATA[python三大神器]]></title>
    <url>%2F2018%2F09%2F10%2Fpython%E4%B8%89%E5%A4%A7%E7%A5%9E%E5%99%A8%2F</url>
    <content type="text"><![CDATA[python三大神器装饰器、生成器、迭代器 装饰器在说装饰器之前先了解一下闭包函数： 12345678910111213141516# 外函数outer()def outer(): # 外函数局部变量，对于内函数来说相当于全局变量 number = 10 # 内函数 def inner(): # 外函数数据的引用 nonlocal number number += 1 # 返回值是内函数inner的引用 return inner # 调用outer函数，用func接收inner函数的引用func = outer()# 调用inner函数 func() 在一个函数里边定义了一个函数 内函数可能会用到外函数的数据 外函数一定有返回值，而且是内函数的引用 装饰器的定义闭包的延伸，外函数传入函数的引用，而且内函数返回函数的调用就是装饰器。 装饰器的作用在不修改函数体的前提下，在函数前面添加功能比如验证等 。 原理直接调用内函数，先执行内函数函数体，即验证的部分，在内函数的返回值的地方返回传入函数的调用，即不被修改的函数体。 12345678910def outer(func): def inner(): return func() return inner# 装饰器的使用 @ ：相当于 func = outer(func) # 即把func的引用替换成outer的返回值，也就是内函数的引用# 然后在内函数中返回原本func的引用的调用，即func的函数体@outerdef func(): pass 内置装饰器python中内置的装饰器有三个：staticmethod、classmethod和property，作用分别是把类中定义的实例方法变成静态方法、类方法和类属性。functools模块提供了两个装饰器：1.wraps(wrapped[, assigned][, updated]):这是一个很有用的装饰器。看过前一篇反射的朋友应该知道，函数是有几个特殊属性比如函数名，在被装饰后，上例中的函数名foo会变成包装函数的名字wrapper，如果你希望使用反射，可能会导致意外的结果。这个装饰器可以解决这个问题，它能将装饰过的函数的特殊属性保留。 12345678910111213141516171819import time import functools def timeit(func): @functools.wraps(func) def wrapper(): start = time.clock() func() end =time.clock() print ‘used:’, end - start return wrapper@timeitdef foo(): print ‘in foo()’foo()print foo.__name__ 首先注意第5行，如果注释这一行，foo.name将是’wrapper’。另外相信你也注意到了，这个装饰器竟然带有一个参数。实际上，他还有另外两个可选的参数，assigned中的属性名将使用赋值的方式替换，而updated中的属性名将使用update的方式合并，你可以通过查看functools的源代码获得它们的默认值。对于这个装饰器，相当于wrapper = functools.wraps(func)(wrapper)。2.total_ordering(cls):这个装饰器在特定的场合有一定用处，但是它是在Python 2.7后新增的。它的作用是为实现了至少lt、le、gt、ge其中一个的类加上其他的比较方法，这是一个类装饰器。如果觉得不好理解，不妨仔细看看这个装饰器的源代码： 1234567891011121314151617181920212223242526def total_ordering(cls): """Class decorator that fills in missing ordering methods""" convert = &#123; '__lt__': [('__gt__', lambda self, other: other &lt; self), ('__le__', lambda self, other: not other &lt; self), ('__ge__', lambda self, other: not self &lt; other)], '__le__': [('__ge__', lambda self, other: other &lt;= self), ('__lt__', lambda self, other: not other &lt;= self), ('__gt__', lambda self, other: not self &lt;= other)], '__gt__': [('__lt__', lambda self, other: other &gt; self), ('__ge__', lambda self, other: not other &gt; self), ('__le__', lambda self, other: not self &gt; other)], '__ge__': [('__le__', lambda self, other: other &gt;= self), ('__gt__', lambda self, other: not other &gt;= self), ('__lt__', lambda self, other: not self &gt;= other)] &#125; roots = set(dir(cls)) &amp; set(convert) if not roots: raise ValueError('must define at least one ordering operation: &lt; &gt; &lt;= &gt;=') root = max(roots) # prefer __lt__ to __le__ to __gt__ to __ge__ for opname, opfunc in convert[root]: if opname not in roots: opfunc.__name__ = opname opfunc.__doc__ = getattr(int, opname).__doc__ setattr(cls, opname, opfunc) return cls 进阶装饰器1.带有参数的装饰器：假设我们前文的装饰器需要完成的功能不仅仅是能在进入某个函数后打出log信息，而且还需指定log的级别，那么装饰器就会是这样的。 123456789101112131415161718192021222324def logging(level): def wrapper(func): def inner_wrapper(*args, **kwargs): print "[&#123;level&#125;]: enter function &#123;func&#125;()".format( level=level, func=func.__name__) return func(*args, **kwargs) return inner_wrapper return wrapper@logging(level='INFO')def say(something): print "say &#123;&#125;!".format(something)# 如果没有使用@语法，等同于# say = logging(level='INFO')(say)@logging(level='DEBUG')def do(something): print "do &#123;&#125;...".format(something)if __name__ == '__main__': say('hello') do("my work") 当带参数的装饰器被打在某个函数上时，比如@logging(level=’DEBUG’)，它其实是一个函数，会马上被执行，只要这个它返回的结果是一个装饰器时，那就没问题。细细再体会一下。2.基于类实现的装饰器装饰器函数其实是这样一个接口约束，它必须接受一个callable对象作为参数，然后返回一个callable对象。在Python中一般callable对象都是函数，但也有例外。只要某个对象重载了call()方法，那么这个对象就是callable的。用类来实现也是也可以的。我们可以让类的构造函数init()接受一个函数，然后重载call()并返回一个函数，也可以达到装饰器函数的效果。 1234567891011class logging(object): def __init__(self, func): self.func = func def __call__(self, *args, **kwargs): print "[DEBUG]: enter function &#123;func&#125;()".format( func=self.func.__name__) return self.func(*args, **kwargs)@loggingdef say(something): print "say &#123;&#125;!".format(something) 3.带有参数的类装饰器如果需要通过类形式实现带参数的装饰器，那么会比前面的例子稍微复杂一点。那么在构造函数里接受的就不是一个函数，而是传入的参数。通过类把这些参数保存起来。然后在重载call方法是就需要接受一个函数并返回一个函数。 123456789101112131415class logging(object): def __init__(self, level='INFO'): self.level = level def __call__(self, func): # 接受函数 def wrapper(*args, **kwargs): print "[&#123;level&#125;]: enter function &#123;func&#125;()".format( level=self.level, func=func.__name__) func(*args, **kwargs) return wrapper #返回函数@logging(level='INFO')def say(something): print "say &#123;&#125;!".format(something) 迭代器迭代器是访问集合元素的一种方式。迭代器对象从集合的第一个元素开始访问，直到所有的元素被访问完结束。迭代器只能往前不会后退，不过这也没什么，因为人们很少在迭代途中往后退。另外，迭代器的一大优点是不要求事先准备好整个迭代过程中所有的元素。迭代器仅仅在迭代到某个元素时才计算该元素，而在这之前或之后，元素可以不存在或者被销毁。这个特点使得它特别适合用于遍历一些巨大的或是无限的集合，比如几个G的文件。 特点a）访问者不需要关心迭代器内部的结构，仅需通过next()方法或不断去取下一个内容 b）不能随机访问集合中的某个值 ，只能从头到尾依次访问 c）访问到一半时不能往回退 d）便于循环比较大的数据集合，节省内存 e）也不能复制一个迭代器。如果要再次（或者同时）迭代同一个对象，只能去创建另一个迭代器对象。enumerate()的返回值就是一个迭代器。 可迭代对象和可迭代器可以直接作用于for循环的对象统称为可迭代对象(Iterable)。 可以被next()函数调用并不断返回下一个值的对象称为迭代器(Iterator)。 所有的Iterable均可以通过内置函数iter()来转变为Iterator。如何判断一个对象是可迭代对象呢？可以通过collections模块的Iterable类型判断。可迭代对象：迭代器是一个对象，不是一个函数；是一个什么样的对象呢？就是只要它定义了可以返回一个迭代器的iter方法，或者定义了可以支持下标索引的getitem方法，那么它就是一个可迭代对象。迭代器：任何实现了iter和next()（python2中实现next()）方法的对象都是迭代器，iter返回迭代器自身，next返回容器中的下一个值。 生成器理解了迭代器以后，生成器就会简单很多，因为生成器其实是一种特殊的迭代器。不过这种迭代器更加优雅。它不需要再像上面的类一样写iter()和next()方法了，只需要一个yiled关键字。 生成器一定是迭代器（反之不成立），因此任何生成器也是以一种懒加载的模式生成值。语法上说，生成器函数是一个带yield关键字的函数。调用生成器函数后会得到一个生成器对象，这个生成器对象实际上就是一个特殊的迭代器，拥有iter()和next()方法。小结：按照鸭子模型理论，生成器就是一种迭代器，可以使用for进行迭代。 第一次执行next(generator)时，会执行完yield语句后程序进行挂起，所有的参数和状态会进行保存。再一次执行next(generator)时，会从挂起的状态开始往后执行。在遇到程序的结尾或者遇到StopIteration时，循环结束。 可以通过generator.send(arg)来传入参数，这是协程模型。 可以通过generator.throw(exception)来传入一个异常。throw语句会消耗掉一个yield。可以通过generator.close()来手动关闭生成器。 next()等价于send(None)]]></content>
  </entry>
  <entry>
    <title><![CDATA[列表生成式与匿名函数]]></title>
    <url>%2F2018%2F09%2F08%2F%E5%88%97%E8%A1%A8%E7%94%9F%E6%88%90%E5%BC%8F%E4%B8%8E%E5%8C%BF%E5%90%8D%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[列表生成式[x * x for x in range(1, 11)] 就是一个列表生成式, 它的基础语法是:[exp for iter_var in iterable]首先迭代 iterable 里所有内容, 每一次迭代, 都把 iterable 里相应内容放到 iter_var 中, 再在表达式 exp 中应用该 iter_var 的内容, 最后用表达式的计算值生成一个新的列表.例如, 把一个 list 中所有的字符串变成小写: 123L = ['Hello', 'World', 'IBM', 'Apple'][s.lower() for s in L]&gt;&gt;&gt; ['hello', 'world', 'ibm', 'apple'] map（）函数map()是 Python 内置的高阶函数，它接收一个函数 f 和一个 list，并通过把函数 f 依次作用在 list 的每个元素上，得到一个新的 list 并返回。例子： 12345678910111213141516171819202122a = [1, 2, 3, 4]b = [x + 1 for x in a]print(b)c = [x for x in map(lambda x, y: x + y, a, b)]print(c)# d = [x for x in c]# print(d)l4 = map(lambda x, y: (x ** y, x + y), [1, 2, 3], [1, 2])for i in l4: print(i)# l4 = map(lambda x, y: (x ** y, x + y), [1, 2, 3], [1, 2, 'a'])# for i in l4:# print(i)l = [1, 2, 3]x = map(None, l)print(x)结果：[2, 3, 4, 5][3, 5, 7, 9](1, 2)(4, 4)&lt;map object at 0x00000191E293EE48&gt; filter（）函数filter()函数是 Python 内置的另一个有用的高阶函数，filter()函数接收一个函数 f 和一个list，这个函数 f 的作用是对每个元素进行判断，返回 True或 False，filter()根据判断结果自动过滤掉不符合条件的元素，返回由符合条件元素组成的新list。例如，要从一个list [1, 4, 6, 7, 9, 12, 17]中删除偶数，保留奇数，首先，要编写一个判断奇数的函数： 12def is_odd(x): return x % 2 == 1 然后，利用filter()过滤掉偶数： 12&gt;&gt;&gt;filter(is_odd, [1, 4, 6, 7, 9, 12, 17])&gt;&gt;&gt;[1, 7, 9, 17] 利用filter()，可以完成很多有用的功能，例如，删除 None 或者空字符串： 1234def is_not_empty(s): return s and len(s.strip()) &gt; 0&gt;&gt;&gt;filter(is_not_empty, ['test', None, '', 'str', ' ', 'END'])&gt;&gt;&gt;['test', 'str', 'END'] 注意: s.strip(rm) 删除 s 字符串中开头、结尾处的 rm 序列的字符。 当rm为空时，默认删除空白符（包括’\n’, ‘\r’, ‘\t’, ‘ ‘)，如下： 1234567&gt;&gt;&gt; a = ' 123'&gt;&gt;&gt; a.strip()'123'&gt;&gt;&gt; a = '\t\t123\r\n'&gt;&gt;&gt; a.strip()'123' reduce函数reduce() 函数会对参数序列中元素进行累积。 函数将一个数据集合（链表，元组等）中的所有数据进行下列操作：用传给 reduce 中的函数 function（有两个参数）先对集合中的第 1、2 个元素进行操作，得到的结果再与第三个数据用 function 函数运算，最后得到一个结果。reduce() 函数在 python 2 是内置函数， 从python 3 开始移到了 functools 模块。例子： 123456789101112131415161718求每个单词出现的次数：from functools import reducestr = "an apple a banana three apple a desk"list = str.split(' ')print(list)def fun(x, y): if y in x: x[y] = x[y] + 1 else: x[y] = 1 return xresult = reduce(fun, list, &#123;&#125;)print(result) 匿名函数格式：lambda arg1,arg2,…..argn:expression #冒号:之前的arg1，arg2…表示它们是这个函数的参数。 #匿名函数不需要return来返回值，表达式本身结果就是返回值。1 匿名函数即没有绑定名字的函数，没有绑定名字，意味着只能用一次就会被回收。2 所以说匿名函数的应用场景就是：某个功能只用一次就结束了。例子： 1234567891011&gt;&gt;&gt; s = "this is\na\ttest" #建此字符串按照正常情形输出&gt;&gt;&gt; s'this is\na\ttest'&gt;&gt;&gt; print s.split() #split函数默认分割:空格，换行符，TAB['this', 'is', 'a', 'test']&gt;&gt;&gt; ' '.join(s.split()) #用join函数转一个列表为字符串'this is a test'等价于&gt;&gt;&gt; (lambda s:' '.join(s.split()))("this is\na\ttest") 无参数的匿名函数： 12345678&gt;&gt;&gt; t = lambda : True #分号前无任何参数&gt;&gt;&gt; t()True等价于下面的def定义的函数&gt;&gt;&gt; def func(): return True&gt;&gt;&gt; func()True 和map及list联合使用： 123456789101112131415&gt;&gt;&gt; import sys&gt;&gt;&gt; showall = lambda x:list(map(sys.stdout.write,x))&gt;&gt;&gt; showall(['Jerry\n','Sherry\n','Alice\n'])JerrySherryAlice&gt;&gt;&gt; showall(['Jerry','Sherry','Alice'])JerrySherryAlice等价于下面&gt;&gt;&gt; showall = lambda x: [sys.stdout.write(line) for line in x]&gt;&gt;&gt; showall(('I\t','Love\t','You!'))I Love You![None, None, None] 求2-50之间的素数： 1234567#素数:只能被1或被自己整除的数&gt;&gt;&gt; nums = range(2,50)&gt;&gt;&gt; for i in nums:nums = filter(lambda x:x==i or x % i,nums)&gt;&gt;&gt; nums[2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47] 求字符串每个单词的长度： 123456&gt;&gt;&gt; sentence = "Welcome To Beijing!"&gt;&gt;&gt; words = sentence.split()&gt;&gt;&gt; lengths = map(lambda x:len(x),words)&gt;&gt;&gt; lengths[7, 2, 8]]]></content>
  </entry>
  <entry>
    <title><![CDATA[单例模式和工厂模式]]></title>
    <url>%2F2018%2F09%2F07%2F%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E5%92%8C%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[单例模式单例模式是一中常见的软件设计模式 ，该模式的主要目的是确保某个类只有一个实例存在。可以减少内存资源的浪费。 在python中实现单例的方法1.使用模块2.使用new3.使用装饰器（decorator）4.使用元类（metaclass） 使用模块其实，Python 的模块就是天然的单例模式，因为模块在第一次导入时，会生成 .pyc 文件，当第二次导入时，就会直接加载 .pyc 文件，而不会再次执行模块代码。因此，我们只需把相关的函数和数据定义在一个模块中，就可以获得一个单例对象了。如果我们真的想要一个单例类，可以考虑这样做： 123456# mysingleton.pyclass My_Singleton(object): def foo(self): pass my_singleton = My_Singleton() 将上面的代码放到mysingleton.py中，然后这样使用： 123from mysingleton import my_singleton my_singleton.foo() 使用new为了使类只能出现一个实例，我们可以使用 new 来控制实例的创建过程，代码如下： 123456789class Singleton(object): __instance = None def __new__(cls, *args, **kw): if not cls._instance: cls.__instance = super(Singleton, cls).__new__(cls, *args, **kw) return cls.__instance class MyClass(Singleton): a = 1 在上面的代码中，我们将类的实例和一个类变量 _instance 关联起来，如果 cls._instance 为 None 则创建实例，否则直接返回 cls._instance。执行情况如下： 12345678&gt;&gt;&gt; one = MyClass()&gt;&gt;&gt; two = MyClass()&gt;&gt;&gt; one == twoTrue&gt;&gt;&gt; one is twoTrue&gt;&gt;&gt; id(one), id(two)(4303862608, 4303862608) 使用装饰器我们知道，装饰器（decorator）可以动态地修改一个类或函数的功能。这里，我们也可以使用装饰器来装饰某个类，使其只能生成一个实例，代码如下： 1234567891011121314from functools import wraps def singleton(cls): instances = &#123;&#125; @wraps(cls) def getinstance(*args, **kw): if cls not in instances: instances[cls] = cls(*args, **kw) return instances[cls] return getinstance @singletonclass MyClass(object): a = 1 在上面，我们定义了一个装饰器 singleton，它返回了一个内部函数 getinstance，该函数会判断某个类是否在字典 instances 中，如果不存在，则会将 cls 作为 key，cls(*args, **kw) 作为 value 存到 instances 中，否则，直接返回 instances[cls]。 使用metaclass元类（metaclass）可以控制类的创建过程，它主要做三件事： 拦截类的创建 修改类的定义 返回修改后的类使用元类实现单例模式的代码如下： 123456789101112131415class Singleton(type): _instances = &#123;&#125; def __call__(cls, *args, **kwargs): if cls not in cls._instances: cls._instances[cls] = super(Singleton, cls).__call__(*args, **kwargs) return cls._instances[cls] # Python2class MyClass(object): __metaclass__ = Singleton # Python3# class MyClass(metaclass=Singleton):# pass 小结Python 的模块是天然的单例模式，这在大部分情况下应该是够用的，当然，我们也可以使用装饰器、元类等方法 工厂模式工厂模式是一个在软件开发中用来创建对象的设计模式。 工厂模式包涵一个超类。这个超类提供一个抽象化的接口来创建一个特定类型的对象，而不是决定哪个对象可以被创建。 为了实现此方法，需要创建一个工厂类创建并返回。 当程序运行输入一个“类型”的时候，需要创建于此相应的对象。这就用到了工厂模式。在如此情形中，实现代码基于工厂模式，可以达到可扩展，可维护的代码。当增加一个新的类型，不在需要修改已存在的类，只增加能够产生新类型的子类。 简短的说，当以下情形可以使用工厂模式： 1.不知道用户想要创建什么样的对象 2.当你想要创建一个可扩展的关联在创建类与支持创建对象的类之间。需求：有一个学雷锋活动，有买米和扫地两个内容，参与的人有大学生和社区志愿者，他们各自的方法不一样。 如果用简单工厂模式实现: 12345678910111213141516171819202122232425262728293031323334353637383940414243# coding=utf-8# factory.py 工厂方法设计模式# 根据传入参数的不同, 而返回对应的对象# 案例:你去一家餐厅,给厨子'番茄'和'鸡蛋',厨子返回给你'番茄炒鸡蛋';给厨子'白糖'和'黄瓜',厨子返回给你'白糖拌黄瓜' class TomatoesAndEgg: def __init__(self): self.data = "男士喜欢吃番茄炒蛋" def getData(self): return self.data class SugarAndCucumber: def __init__(self): self.data = 123456 def getData(self): return self.data # 工厂方法: 根据传入参数的不同, 而返回对应的对象def cook_factory(sex): if sex == "man": food = TomatoesAndEgg elif sex == "woman": food = SugarAndCucumber else: raise ValueError("请出入正确的性别: &#123;&#125;".format(sex)) return food() if __name__ == "__main__": man = cook_factory("man") woman = cook_factory("woman") data_man = man.getData() # 返回String类型数据 data_woman = woman.getData() # 返回int类型数据 # getData()返回不同类型的数据, 这在实际开发中是很常见的 print(data_man) # =&gt; 男士喜欢吃番茄炒蛋 print(data_woman) # =&gt; 123456]]></content>
  </entry>
  <entry>
    <title><![CDATA[FastDFS]]></title>
    <url>%2F2018%2F09%2F06%2FFastDFS%2F</url>
    <content type="text"><![CDATA[什么是FastFDSFastDFS 是用 c 语言编写的一款开源的分布式文件系统。FastDFS 为互联网量身定制， 充分考虑了冗余备份、负载均衡、线性扩容等机制，并注重高可用、高性能等指标，使用 FastDFS 很容易搭建一套高性能的文件服务器集群提供文件上传、下载等服务。FastDFS 架构包括 Tracker server 和 Storage server。客户端请求 Tracker server 进行文 件上传、下载，通过 Tracker server 调度最终由 Storage server 完成文件上传和下载。 Tracker server 作用是负载均衡和调度，通过 Tracker server 在文件上传时可以根据一些 策略找到 Storage server 提供文件上传服务。可以将 tracker 称为追踪服务器或调度服务器。 Storage server 作用是文件存储，客户端上传的文件最终存储在 Storage 服务器上， Storageserver 没有实现自己的文件系统而是利用操作系统 的文件系统来管理文件。可以将 storage 称为存储服务器。 Tracker: 管理集群，tracker 也可以实现集群。每个 tracker 节点地位平等。收集 Storage 集群的状态。 Storage: 实际保存文件， Storage 分为多个组，每个组之间保存的文件是不同的。每 个组内部可以有多个成员，组成员内部保存的内容是一样的，组成员的地位是一致的，没有 主从的概念。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Celery]]></title>
    <url>%2F2018%2F09%2F06%2FCelery%2F</url>
    <content type="text"><![CDATA[Celery介绍1.Celery 是一个 基于python开发的分布式异步消息任务队列，通过它可以轻松的实现任务的异步处理。用于解决程序中耗时的任务。2.优点：简单，高可用，快速，灵活3.Celery安装和使用：Celery默认brober是Rabbit MQ，可以改为Redis数据库，只需要配置：brober_url=’redis://127.0.0.1:6379/14’4.项目中异步的执行函数main.py 1234567891011121314151617from celery import Celeryfrom . import configimport os# 设置django的配置os.environ.setdefault("DJANGO_SETTINGS_MODULE", "meiduo.settings")# 创建对象app = Celery('meiduo')# 加载配置app.config_from_object(config)# 初始化任务# 在指定的包中找到tasks.py 文件，在这个文件中找@app.task的函数app.autodiscover_tasks([ 'celery_tasks.sms', 'celery_tasks.email', 'celery_tasks.html']) 在异步包中添加需要执行异步的任务tasks 1234567from utils.ytx_sdk.sendSMS import CCPfrom celery_tasks.main import app@app.task(name='sms_send')def sms_send(mobile, sms_code, expires, template_id): # CCP.sendTemplateSMS(mobile, sms_code, expires, template_id) print(sms_code) 6.在需要的视图中执行异步任务：异步对象名.delay(任务所需参数）——–调用异步任务7.启动celery服务celery -A celery_tasks.main worker -l info8.celery构架组成：中间代理人：brober任务执行单元worker，也叫职程执行结果存储backend]]></content>
  </entry>
  <entry>
    <title><![CDATA[Restful风格]]></title>
    <url>%2F2018%2F09%2F06%2FRestful%E9%A3%8E%E6%A0%BC%2F</url>
    <content type="text"><![CDATA[Rest即Representational State Transfer ,直译为‘表现层状态转化’，最大的几个特点是：资源， 统一接口，URI和无状态。 Restful风格特点1.资源：以json(或其他Representation)为载体的、面向用户的一组数据集。2.统一接口：Restful规定数据的操作，增删改查分别对应着Http方法，GET用来获取资源，POST用来新建资源（也可以用于更新资源），PUT用来更新资源，DELETE用来删除资源，这样就统一了数据操作的接口，仅通过HTTP方法，就可以完成对数据的所有增删查改工作。即：GET（SELECT）：从服务器取出资源（一项或多项）。POST（CREATE）：在服务器新建一个资源。PUT（UPDATE）：在服务器更新资源（客户端提供完整资源数据）。PATCH（UPDATE）：在服务器更新资源（客户端提供需要修改的资源数据）。DELETE（DELETE）：从服务器删除资源。 URI可以用一个URI（统一资源定位符）指向资源，即每个URI都对应一个特定的资源。要获取这个资源，访问它的URI就可以，因此URI就成了每一个资源的地址或识别符。 无状态所谓无状态的，即所有的资源，都可以通过URI定位，而且这个定位与其他资源无关，也不会因为其他资源的变化而改变。因为Restful风格是无状态的，所以认证机制就尤为重要，常用的认证机制有：Basic auth，token auth和OAuth。]]></content>
      <tags>
        <tag>Restful风格</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MVT与MCV]]></title>
    <url>%2F2018%2F09%2F06%2FMVT%E4%B8%8EMCV%2F</url>
    <content type="text"><![CDATA[MVC的核心思想：解耦，让不同的代码之间降低耦合，增强代码的可移植性和可扩展性，实现向后兼容。 Web MVC各部分的功能：1.Model：主要封装了对数据库层的的访问，对数据库中的数据进行增，删，改，查操作。2.View：用于封装结果，生成页面html内容与用户进行交互。3.Controller：用于接受请求，处理业务逻辑，与Model和View交互，返回结果。 MVT： Django 遵循MVC设计，并有一个专有名词：MVT MVT各部分的功能1.Model： 负责与数据库交互，进行数据操作。2.View：与MVC中的C的功能一样，接受请求，处理业务，返回应答。3.Template： 与MVC中的V的功能一样，负责封装要返回的html。]]></content>
  </entry>
  <entry>
    <title><![CDATA[python的PEP8规范]]></title>
    <url>%2F2018%2F09%2F06%2FPEP8%E7%BC%96%E7%A0%81%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[PEP8 Python 编码规范代码编程 缩进，4个空格的缩进，不使用Tab，更不能混合使用Tab和空格。 每行最大长度79，换行可以使用反斜杠，最好使用圆括号。 类和top-level函数定义之间空两行；类中的方法定义之间空一行；函数内逻辑无关段落之间空一行；其他地方尽量不要再空行。 文档编排1.模块内容的顺序：模块说明和docstring—import—globals&amp;constants—其他定义。其中import部分，又按标准、三方和自己编写顺序依次排放，之间空一行。2.不要在一句import中多个库，比如import os, sys不推荐。3.如果采用from XX import XX引用库，可以省略‘module.’，都是可能出现命名冲突，这时就要采用import XX。 空格的使用总体原则，避免不必要的空格。 1 各种右括号前不要加空格。2 逗号、冒号、分号前不要加空格。3 函数的左括号前不要加空格。如Func(1)。4 序列的左括号前不要加空格。如list[2]。5 操作符左右各加一个空格，不要为了对齐增加空格。6 函数默认参数使用的赋值符左右省略空格。7 不要将多句语句写在同一行，尽管使用‘；’允许。8 if/for/while语句中，即使执行语句只有一句，也必须另起一行。 注释 总体原则，错误的注释不如没有注释。所以当一段代码发生变化时，第一件事就是要修改注释！ 注释必须使用英文，最好是完整的句子，首字母大写，句后要有结束符，结束符后跟两个空格，开始下一句。如果是短语，可以省略结束符。 命名规范总体原则，新编代码必须按下面命名风格进行，现有库的编码尽量保持风格。 1 尽量单独使用小写字母‘l’，大写字母‘O’等容易混淆的字母。2 模块命名尽量短小，使用全部小写的方式，可以使用下划线。3 包命名尽量短小，使用全部小写的方式，不可以使用下划线。4 类的命名使用CapWords的方式，模块内部使用的类采用_CapWords的方式。5 异常命名使用CapWords+Error后缀的方式。6 全局变量尽量只在模块内有效，类似C语言中的static。实现方法有两种，一是all机制;二是前缀一个下划线。7 函数命名使用全部小写的方式，可以使用下划线。8 常量命名使用全部大写的方式，可以使用下划线。9 类的属性（方法和变量）命名使用全部小写的方式，可以使用下划线。9 类的属性有3种作用域public、non-public和subclass API，可以理解成C++中的public、private、protected，non-public属性前，前缀一条下划线。11 类的属性若与关键字名字冲突，后缀一下划线，尽量不要使用缩略等其他方式。12 为避免与子类属性命名冲突，在类的一些属性前，前缀两条下划线。比如：类Foo中声明a,访问时，只能通过Foo._Fooa，避免歧义。如果子类也叫Foo，那就无能为力了。13 类的方法第一个参数必须是self，而静态方法第一个参数必须是cls。 编码建议1 编码中考虑到其他python实现的效率等问题，比如运算符‘+’在CPython（Python）中效率很高，都是Jython中却非常低，所以应该采用.join()的方式。2 尽可能使用‘is’‘is not’取代‘==’，比如if x is not None 要优于if x。3 使用基于类的异常，每个模块或包都有自己的异常类，此异常类继承自Exception。4 异常中不要使用裸露的except，except后跟具体的exceptions。5 异常中try的代码尽可能少。]]></content>
      <tags>
        <tag>PEP8规范</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F09%2F03%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
